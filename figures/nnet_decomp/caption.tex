Neural networks can be used to compress data into a few, representative directions. In order to properly condition the weights of the neural network to be close to an optimal solution, the weights of each layer are pre-trained so that the layer reproduces the output of the previous layer (left). These layers are then stacked into a funnel first decreasing in size (the encoder) and then increasing in size (the decoder). Finally, the weights are fine-tuned to minimize reconstruction error (right).