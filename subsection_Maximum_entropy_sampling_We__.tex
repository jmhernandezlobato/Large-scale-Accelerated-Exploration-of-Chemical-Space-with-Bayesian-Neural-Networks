\subsection{Maximum entropy sampling}

We now evaluate the performance of the maximum entropy sampling (MES) method. For this, we first randomly split all the available molecules into an initial training set of size 2000 (Malaria and One-dose) or 25,000 (CEP), a test set with 10\% of the molecules and a pool set with all the other remaining molecules. After that, we iteratively increase the size of the training set by collecting data from the pool set. For this, we use batches of size 200 (Malaria and One-dose) or 500 (CEP). Before each sampling step, a Bayesian neural network is fit with PBP on the training data and its predictive root-mean-squared-error (RMSE) is computed on the test data, which is kept fixed during all the experiment. The resulting network is then used to collect data using the MES strategy. For comparison, we also include results for a Monte Carlo approach that collects data by sampling molecules from the pool set uniformly at random.

Figure \ref{fig:max_entropy} shows the average results obtained by each method across 50 (Malaria and One-dose) or 10 (CEP) repetitions of the experiments. These plots indicate that the MES method produces lower RMSE values and is therefore able to discover highly informative sets of molecules. Note that, for the CEP data set, the trajectory of the RMSE curve is much noisier for the Monte Carlo sampler than for the MES sampler. This increased robustness seems to be another advantage of the MES approach.


The plots in Figure \ref{fig:max_entropy} show that the gains of the MES strategy are larger in Malaria and One-dose than in CEP. 

This result is not surprising when the distribution of pairwise distances derived using the network based components is considered. The result is most pronounced for the Malaria dataset and the One-Dose dataset, which show the most skewed distribution.  The One-Dose dataset has the lowest mean of the three sets, which suggests that molecules picked randomly will most likely have a small 'component distance', this suggests that they will be similar in the eyes of the neural network, and thus contribute little information entropy to the training set. Whilst the Malaria dataset has a higher mean, it exhibits a long-tailed distribution, which is again problematic for a Monte Carlo sampling approach.  In comparison to those, pairwise distances within the Clean Energy Project dataset are fairly close to being normally distributed.  This is realized in the results of the sampling, where Monte Carlo - despite displaying significantly more variance in its performance - does not perform as poorly when compared to the maximum entropy sampling methodology.

It is also worthwhile recalling that this method selects molecules without considering their contribution to the overall error of the training set; instead utilizing the predictive uncertainty of the model for selecting which molecules to add to the training set. Thus, it represents a purely information-based approach and clearly demonstrates the power of exploiting the underlying information landscape for intelligently constructing informative libraries.