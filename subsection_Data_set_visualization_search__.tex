\subsection{Data set visualization: search landscape plots}

In this section we present a 2D visualization of the search space for each of the previous data sets. We refer to the resulting 2D plots as \emph{search landscapes}. These plots are useful to understand the individual characteristics of the search problem in each data set. They are generated by using neural networks to perform a non-linear 2D projection of the molecules that form each data set \cite{Hinton_2006}.

We instead utilize an alternative measure, in which a neural network itself is used to compress the data into a reasonable number of dimensions,  upon which a visual inspection can reveal the diversity of the data set

When analyzing data sets for qualities such as diversity, it is important to make the distance measure consistent with the predictive model.  For example, if the prediction were made with a Gaussian process, it would be wise to use the distance model built into the kernel to analyze the diversity of the data sets studied.  This becomes somewhat more complex when the predictive method does not have a well defined distance measure built into it, such as a neural network.  Simply analyzing the diversity of the inputs through the use of a Tanimoto distance histogram, for example, is potentially a dangerous path since it does not acknowledge the highly connected nature of the neurons in a neural network.  We instead utilize an alternative measure, in which a neural network itself is used to compress the data into a reasonable number of dimensions, \cite{Hinton_2006} upon which a visual inspection can reveal the diversity of the data set.

This is achieved through training an unsupervised neural network, of which the loss function of each layer is determined by how well the output matches that of the previous layer.  Through sequential reduction in the number of neurons, the principle components of an input signal are amplified, and can be sampled.  To fine tune the weights of this neural network, the funneling architecture is mirrored, and the weights adjusted so that a loss function comparing the input and output of the network is minimized.

The distributions of these network derived principle components were further investigated through the calculation of pairwise component distances. These distances were normalized so that the maximum distance was set at 1.0, and the minimum set to be 0.0. It can be seen from Figure \ref{fig:dist_hists}, that all of the sets are reasonably diverse in the eyes of the neural network.  As seen from figure 3, these sets are reasonably diverse in the eyes of the neural network. This statement may be counterintuitive from the chemical perspective, as perhaps one can think that molecules to carry out a specific task are likely to be more chemically similar. Global diversity measures can often give a misleading view into how models work on data. These measures can be thought of as a map of the local surroundings in chemical space.  To extend the metaphor, if you are looking to find the best place for a picnic, it is more helpful to have a streetmap than a globe.

The underlying information derived from these network derived components can be further investigated through the use of a plot we call an 'information landscape'.  In this plot, chemical space (as described by the components, which are bound between 0 and 1) is split into areas of size 0.2x0.2 arbitrary units. The mean value for the targets contained within each area is calculated, and determines the color of that area.  In order to visualize the distribution of molecules within this depiction of chemical space, a kernel density estimate is used to plot contour lines.  Additionally, the top 100 molecules, ranked according to their target value, are plotted as points on the surface.  By analyzing the distribution of the data, alongside the location of extreme molecules, it is easy to classify the data into types of information landscape.  In Figure \ref{fig:info_landscapes}, we can see the information landscapes created to describe each of the data sets used within this study.  The Clean Energy Project dataset is striking in the strength of the input/property relationship --- the majority of the top molecules are concentrated in a relatively small area of chemical space.  Additionally, in this dataset, there is a clear trend for worsening performance as the Y-axis is ascended.  This is not the case for the other two datasets, in which the `good' areas of chemical space are more randomly distributed.  It is interesting to observe the One-Dose data set, in which there are two clear families of extreme molecules, one towards the top of the plot and one towards the bottom left.  This could be indicative of two different approaches taken in the literature to approach the problem of developing good treatments for this particular type of cancer.