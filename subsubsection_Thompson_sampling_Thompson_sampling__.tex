\subsubsection{Thompson sampling}

Thompson sampling (TS) \cite{Thompson_1933} is a simple heuristic for efficiently identifying the optimal element in a set. Solving efficiently this problem with a small number of evaluations of the fitness function requires to attain an optimal exploration/exploitation trade-off. A strong property of TS  is that this is performed automatically without the need for the introduction of additional parameters that would specify the trade-off explicitly and that would themselves require optimization. Another advantage of Thompson sampling is that it can be modified in a straight forward manner for the collection of batches of data in parallel. The following lines describe the implementation of Thompson sampling for the efficient collection of $N$ new measurements in parallel:
\begin{enumerate}
\item A very small number of molecules are selected randomly, and ground truth values are calculated
\item A Bayesian neural network is trained with PBP on this training data
\item The model network weights are sampled $N$ times from their posterior distribution given the collected data, providing a set of deterministic neural networks.
\item Each deterministic neural network makes predictions for all the remaining molecules.
\item For each deterministic neural network, the set of unique molecules with highest score is selected, ground truth values calculated, and added to the training set.
\item Steps 2-5 are repeated
\end{enumerate}
By sampling the weight distributions in the Bayesian neural network, we produce a set of deterministic neural networks, the weights of which vary across the set in a manner directly related to the uncertainty of the probabilistic model in their value.  Thus, a balance in the search for extreme molecules is achieved without directly imposing any external measure of molecular diversity - which is in itself an area of intense study \cite{Maldonado_2006}.