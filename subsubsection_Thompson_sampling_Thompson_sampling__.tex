\subsubsection{Thompson sampling}

Thompson sampling (TS) \cite{Thompson_1933} is a simple heuristic for identifying the optimal element in a set. Solving this problem efficiently, that is, with a small number of evaluations of the fitness function, requires to attain an optimal exploration/exploitation trade-off. TS does this automatically, without having to use additional parameters for specifying the trade-off explicitly, which would themselves require optimization. Another advantage of TS is that it can be easily used
in the batch evaluation setting where multiple measurements are collected simultaneously. Furthermore, the process for generating each new batch of molecules can be implemented in a distributed way across different nodes in a computer cluster. This is important to speed up computations, especially when the batch size is very large and the library of candidate molecules contains millions of elements. The following lines describe the implementation of TS for collecting data in parallel using batches of $N$ molecules:
\begin{enumerate}
\item A small number of molecules are selected uniformly at random from the library of candidate molecules and measurements for their ground truth values are obtained.
\item A Bayesian neural network is trained with PBP on the data collected so far.
\item The network weights are sampled $N$ times from the posterior approximation computed by PBP. This results in $N$ deterministic neural networks with known weight values. 
\item Each of the $N$ deterministic neural networks makes predictions on all the remaining molecules. For each of the $N$ deterministic neural networks, we select the set of top $N$ molecules with highest predicted scores.
\item A batch with the $N$ molecules to be evaluated next is selected. For this, we iterate over the $N$ sets with $N$ molecules generated in the previous step and select from each set the molecule with highest ranking in that set that has not been selected before.
\item Steps 2-5 are repeated
\end{enumerate}
By sampling the weight distributions in the Bayesian neural network, we produce a set of deterministic neural networks, the weights of which vary across the set in a manner directly related to the uncertainty of the probabilistic model in their value.  Thus, a balance in the search for extreme molecules is achieved without directly imposing any external measure of molecular diversity - which is in itself an area of intense study \cite{Maldonado_2006}.