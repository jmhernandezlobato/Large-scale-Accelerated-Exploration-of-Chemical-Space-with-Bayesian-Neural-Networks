\subsubsection{Comparison with $\epsilon$-greedy approaches}

We can easily modify the greedy baseline from the previous section to include some amount of exploration. For example, by replacing a small fraction of the molecules in each batch with molecules chosen uniformly at random. This approach is often called $\epsilon$-greedy \cite{watkins1989learning}, where the variable $\epsilon$ indicates the fraction of molecules that are sampled uniformly at random. The disadvantage of the $\epsilon$-greedy approach is that it requires the tuning of $\epsilon$ to the problem of interest. By contrast, TS 
automatically adjusts the amount of exploration. 

\begin{table}
\centering
\begin{tabular}{lr@{$\pm$}l}
\hline
\bf{Method}& \multicolumn{2}{c}{\bf{Rank}}\\
\hline
$\epsilon = 0.01$ & 3.42 & 0.28 \\
$\epsilon = 0.025$ & 3.02 & 0.25 \\
$\epsilon = 0.05$ & 2.86 & 0.23 \\
$\epsilon = 0.075$ & 3.20 & 0.26 \\
TS & \bf{2.51} & \bf{0.20} \\
\hline
\end{tabular}
\caption{Average rank obtained by each method.}\label{table1}
\end{table}

We compared TS with different versions of $\epsilon$-greedy in the same way as above, using $\epsilon = 0.01, 0.025, 0.05$ and $0.075$. The experiments with the One-dose and the Malaria data sets are similar to the ones done before. However, we now sub-sample the CEP data set to be able to average across 50 different realizations of the experiment: we choose 4,000 molecules uniformly at random and then collect data in batches of size 50 across 50 different repetitions of the screening process. We compute the average rank obtained by each method across the $3\times 50 = 150$ simulated screening experiments. A ranking equal to 1 indicates that the method always obtains the highest recall at the end of the experiment, while a ranking equal to 5 indicates that the method always obtains the worst recall value. Table \ref{table1} shows that the lowest average rank is obtained by TS, which achieves better exploration-exploitation trade-offs than the $\epsilon$-greedy approaches.
