\section{Conclusion}

We have proposed to use Bayesian neural networks as the workhorse for building adaptive design tools to accelerate high-throughput screening experiments. Bayesian neural networks can be trained on large amounts of data and, by using adaptive basis functions, they can learn feature representations that improve their statistical efficiency. These are properties that alternative methods for adaptive design, e.g., Gaussian processes, do not have. Working with large Bayesian neural networks and large amounts of data was traditionally challenging because of the lack of tools for accurate approximate inference. We have avoided this problem by leveraging on a recent advance in this area called probabilistic back-propagation.

We have addressed two different design problems. The first one

for adaptive design tool to


process by sequentially identifying the most useful experiments to be performed
next. However, existing adaptive design methods have shortcomings that limit
their applicability to the molecule search problem. First, they lack
scalability and cannot work with the large amounts of data that are required to
successfully navigate chemical space. Second, they are unable to learn feature
representations for the data, which reduces their statistical efficiency. To
avoid these limitations, we propose an alternative approach based on the
combination of Bayesian neural networks with probabilistic active learning. Our
methods are computationally and statistically efficient by leveraging on recent
advances in approximate Bayesian inference. Thompson
sampling is used to quickly identify molecules with optimal properties.
Maximum entropy sampling is used
to find small sets of molecules with good interpolation and extrapolation properties.
Our techniques generate enriched libraries of compounds in a fraction
of the time required by a stochastic (Monte Carlo) search approach and with
more robustness than a purely greedy search strategy.

We describe a method which utilizes techniques derived from information theory and machine learning to guide an intelligent search of local areas of chemical space, and its application to the discovery of novel photovoltaic materials and therapeutic molecules.  In order to understand the performance of these intelligent searching methods, we also present a novel component reduction algorithm, based upon the use of unsupervised neural networks.  This demonstrates the diversity of the datasets through the eyes of a neural network, and provides a means of analysing diversity through the components which are most strongly expressed through the neural network.  

Our results demonstrate how the underlying uncertainty in predictive values can be exploited through the use of maximum entropy sampling to provide the which optimially balance predictive power against the size of the molecular library. If the search can be formulated as a classic optimization problem, we show how Thompson sampling can be used to quickly and robustly locate extreme molecules by balancing exploration of the underlying information, with exploitation of the predictive model provided by a Bayesian neural network. This resulted in significant increases in the rate of discovery, displaying significant potential for improving the current model of molecular discovery, especially within the virtual realm.
