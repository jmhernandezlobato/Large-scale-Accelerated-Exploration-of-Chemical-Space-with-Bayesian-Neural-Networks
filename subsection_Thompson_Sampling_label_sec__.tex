\subsection{Thompson Sampling}\label{sec:thompson_sampling}

We evaluate the gains produced by Thompson sampling (TS) in experiments simulating a high throughput virtual screening setting. In these experiments, we sequentially sample molecules from libraries of candidate molecules given by the data sets from Section \ref{sec:data_sets}. After each sampling step, we calculate the 1\% recall, that is, the fraction of the top 1\% of molecules from the original library that are found among the sampled ones. For the CEP data set, we compute recall by focusing on molecules with power conversion efficiency larger than 10\%. In all data sets, each sampling step involves selecting a batch of molecules among those that have not been sampled so far. In the Malaria and One-dose data sets we use batches of size 200. These data sets contain each one about 20,000 molecules. By contrast, the CEP data set contains 2 million molecules. In this latter case, we use batches of size 500. In these experiments, we use Bayesian neural networks with one hidden layer containing 100 units.

We compare the performance of TS with that of two baselines. The first one, \emph{greedy}, is a sampling strategy that only considers exploitation and does not perform any exploration. We implement this approach by selecting molecules according to the average of the probabilistic predictions generated by PBP. That is, the greedy approach ignores any variance in the predictions of the Bayesian neural network and generates batches by just ranking molecules according to the mean of the predictive distribution given by PBP. The second baseline is a Monte Carlo approach in which the batches of molecules are selected uniformly at random. These two baselines are examples of techniques that, as the proposed TS method, can be easily implemented in a large scale setting in which the library of candidate molecules contains millions of elements and data is sampled using large batch sizes.

In the Malaria and One-dose data sets, we average across 50 different realizations of the experiments. This is not possible in the CEP data set, which is 100 times larger than the two other data sets. In the CEP case, we report results for a single realization of the experiment (in a second realization we obtained similar results). 
Figure \ref{fig:thompson_1pc} shows the recall obtained by each method in the data sets from 
Section \ref{sec:data_sets}. TS significantly outperforms the Monte Carlo approach, and also offers better performance than greedy sampling. This shows the importance of building in exploration into the sampling strategy, rather than relying on purely exploitative methods. The greedy approach performs best in the CEP data set. In this case, the greedy strategy initially finds better molecules than TS, but after a while TS overtakes, probably because a promising area of chemical space 
initially discovered by the greedy approach starts to become exhausted. The good results of the greedy strategy in the CEP data set are also explained by the search landscapes from Figure \ref{fig:info_landscapes}. The plot for CEP clearly contains a single cluster of interesting molecules, while in One-dose and Malaria the interesting molecules are more spread out.

The previous results allow us to consider the savings produced by adaptive design strategies. In the CEP data set, TS achieves about 20 times higher recall values than the Monte Carlo approach, which is comparable to the exhaustive enumeration that was used to collect the CEP data. We estimate that, with adaptive design strategies, the CEP virtual screening process would have taken 1,500 CPU years instead of the 30,000 that were actually used. Regarding the One-dose and Malaria data sets, TS can locate in both sets about 70\% of the top 1\% molecules by sampling approximately 6,000 molecules. By contrast, the Monte Carlo approach would require sampling 14,000 molecules. This represents a significant reduction in the discovery time for new therapeutic molecules and savings in the economic costs associated with molecule synthesis and testing.

